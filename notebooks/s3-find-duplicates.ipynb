{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import boto3\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('Find and remove duplicate objects from an AWS S3 bucket')\n",
    "parser.add_argument('bucketName', help='S3 bucket to search')\n",
    "\n",
    "args = parser.parse_args() \n",
    "myBucket = args.bucketName\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "print('Starting search for duplicate objects\\n')\n",
    "\n",
    "lastReqLength = 1000\n",
    "lastKey = \"\"\n",
    "existing = {}\n",
    "duplicateObjects = []\n",
    "duplicates = []\n",
    "\n",
    "objectCount = 0\n",
    "duplicatesCount = 0\n",
    "\n",
    "while lastReqLength == 1000:\n",
    "    if (objectCount == 0):\n",
    "        myObjects = s3.list_objects_v2(Bucket=myBucket)\n",
    "    else:\n",
    "        myObjects = s3.list_objects_v2(Bucket=myBucket,StartAfter=lastKey)\n",
    "    lastReqLength = len(myObjects['Contents'])\n",
    "    objectCount += lastReqLength\n",
    "    for obj in myObjects['Contents']:\n",
    "        lastKey = obj['Key']\n",
    "        thisKey = obj['Key']\n",
    "        thisSize = obj['Size']\n",
    "        thisEtag = obj['ETag']\n",
    "        if  thisSize > 0:\n",
    "            if thisEtag in existing:\n",
    "                #duplicate found:\n",
    "                print('!!Duplicate: - %s - %s' % (existing[thisEtag], thisKey))\n",
    "                duplicatesCount += 1\n",
    "                duplicateObjects.append(existing[thisEtag])\n",
    "                duplicates.append(thisKey)\n",
    "            else:\n",
    "                existing[thisEtag] = thisKey\n",
    "\n",
    "print(f\"Found {duplicatesCount} duplicates\")\n",
    "\n",
    "if (len(duplicateObjects) > 0):\n",
    "    s3res = boto3.resource('s3')\n",
    "\n",
    "    for i in range(len(duplicateObjects)):\n",
    "        parts1 = duplicateObjects[i].rpartition('-')\n",
    "        parts2 = duplicates[i].rpartition('-')\n",
    "\n",
    "        objNumberWithExtension = parts1[-1]\n",
    "        prefix = parts1[0]\n",
    "        addition = parts2[0].replace('MAIN/', '')\n",
    "\n",
    "        newName = prefix + '-' + addition + '-' + objNumberWithExtension\n",
    "\n",
    "        print('Copying ' + duplicateObjects[i] + ' to ' + newName)\n",
    "        s3res.Object(myBucket, newName).copy_from(CopySource=myBucket+'/'+duplicateObjects[i])\n",
    "\n",
    "        print('Deleting ' + duplicateObjects[i] + ' and ' + duplicates[i])\n",
    "        s3res.Object(myBucket, duplicateObjects[i]).delete()\n",
    "        s3res.Object(myBucket, duplicates[i]).delete()\n",
    "        \n",
    "print('Copy & delete complete.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
